{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remarques\n",
    "* \n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from string import digits\n",
    "import pandas_profiling\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# ignore some warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load the data set into a pandas dataframe\n",
    "data_to_learn = pd.read_excel('IPO_data_to_learn.xlsx')\n",
    "data_to_predict = pd.read_excel('IPO_data_to_predict.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add predictions \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn['P1'] = data_to_learn.closeDay1 > data_to_learn.offerPrice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "We clean the data to learn from, and we apply the same cleaning to the data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below we see that the Unnamed_0 column represent some kind of indexing on the data which we don't need, hence it makes sence to drop that column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn[\"Unnamed: 0\"].unique().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "data_to_predict.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We decided to use pandas_profiling to output a full report of our dataset, we will then proceed to data cleaning accordingly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.profile_report(style={'full_width':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = data_to_learn.profile_report(title='IPO data Profiling Report')\n",
    "profile.to_file(output_file=\"data_profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_to_learn.corr()\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "ax = sns.heatmap(data=df, xticklabels=df.columns, square=True, annot=True, center=0, cbar=False)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.title('Features Inter-correlation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Dropping highly correlated rows\n",
    "\n",
    "We see from the correlation matrix the following interesting correlations:\n",
    "- `ipoSize` and `totalProceeds` : 1.0\n",
    "- `amountOnProspectus` and `totalProceeds`: 1.0\n",
    "- `reputationSum` and `nUnderwriters`: 0.96\n",
    "\n",
    "We choose to drop `ipoSize`, `amountOnProspectus` and `reputationSum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.drop([\"ipoSize\", \"amountOnProspectus\", 'reputationSum'], axis=1, inplace=True)\n",
    "data_to_predict.drop([\"ipoSize\", \"amountOnProspectus\", 'reputationSum'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Depending on the distribution of the variable, we replace missing values using the Mean or Variance: If the distribution is skewed or heavy tailed we use the median because it's more robust to outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For feature city we dropped the only record which had NaN because it also had NaN in other columns\n",
    "data_to_learn.dropna(subset=['city'], inplace = True)\n",
    "data_to_predict.dropna(subset=['city'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It made sence to give the value 0 to the missing values in leverage as it's the most common value \n",
    "#[https://www.thebalancesmb.com/how-leverage-can-benefit-your-business-398312]\n",
    "data_to_learn['leverage'].fillna(value=0, inplace=True)\n",
    "data_to_predict['leverage'].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For feature blueSky, we replaced missing values by th evalue zero, \n",
    "#because in some states of the US there are no Blue Sky expenses.\n",
    "#[https://www.colonialstock.com/blue-sky-state-filing-fees.htm]\n",
    "data_to_learn['blueSky'].fillna(value=0, inplace=True)\n",
    "data_to_predict['blueSky'].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For features age, bookValue, investmentReceived, managementFee we used the median\n",
    "values = {'age': data_to_learn[\"age\"].median(),\\\n",
    "          'bookValue': data_to_learn[\"bookValue\"].median(),\\\n",
    "          'investmentReceived': data_to_learn[\"investmentReceived\"].median(),\\\n",
    "          'managementFee': data_to_learn[\"managementFee\"].median(),\\\n",
    "          'commonEquity': data_to_learn[\"commonEquity\"].median(),\\\n",
    "          'commonEquity.1': data_to_learn[\"commonEquity.1\"].median(),\\\n",
    "          'investmentReceived': data_to_learn[\"investmentReceived\"].median(),\\\n",
    "          'nExecutives': data_to_learn[\"nExecutives\"].median(),\\\n",
    "          'netIncome': data_to_learn[\"netIncome\"].median(),\\\n",
    "          'nVCs': data_to_learn[\"nVCs\"].median(),\\\n",
    "          'patRatio': data_to_learn[\"patRatio\"].median(),\\\n",
    "          'priorFinancing': data_to_learn[\"priorFinancing\"].median(),\\\n",
    "          'roa': data_to_learn[\"roa\"].median(),\\\n",
    "          'sharesOfferedPerc': data_to_learn[\"sharesOfferedPerc\"].median(),\\\n",
    "          'totalAssets': data_to_learn[\"totalAssets\"].median(),\\\n",
    "          'totalRevenue': data_to_learn[\"totalRevenue\"].median()\n",
    "         }\n",
    "\n",
    "data_to_learn.fillna(value=values, inplace=True)\n",
    "data_to_predict.fillna(value=values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## closeDay1 is what we want to predict\n",
    "## We drop the NaN values since it is akin to non-label data and they only represent 3% of the data\n",
    "\n",
    "print(\"closeDay1 == NaN: \", data_to_learn.closeDay1.isna().sum())\n",
    "print(\"closeDay1 == NaN: \", data_to_learn.closeDay1.isna().sum()/data_to_learn.closeDay1.shape[0]*100, '%')\n",
    "\n",
    "data_to_learn = data_to_learn.dropna(subset=['closeDay1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN rf by empty string \n",
    "\n",
    "data_to_learn.fillna('', inplace=True)\n",
    "data_to_predict.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's give our columns more meaningful names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.rename(columns={\n",
    "    \"commonEquity\": \"commonEquityPercentage\",\\\n",
    "    \"commonEquity.1\": \"commonEquity\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### patRatio\n",
    "\n",
    "We get rid of infinite values and set them to 0 since they correspond to (occurences of \"patent\" in the rf)/(length of rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.patRatio[data_to_learn.patRatio == np.inf].count()\n",
    "\n",
    "data_to_learn.patRatio.replace(np.inf, 0.0, inplace=True)\n",
    "data_to_predict.patRatio.replace(np.inf, 0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City\n",
    "We clean the City feature: we remove numbers to avoid duplicates and leading and trailing whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove numbers to avoid duplicates and leading and trailing whitespaces\n",
    "data_to_learn[\"city\"] = data_to_learn[\"city\"].str.replace('\\d+', '').str.strip()\n",
    "data_to_predict[\"city\"] = data_to_predict[\"city\"].str.replace('\\d+', '').str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### industryFF5, industryFF12, industryFF48\n",
    "\n",
    "They are industry classifications with respectivelly 5, 12 and 48 categories.\n",
    "\n",
    "We will label encode them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.industryFF5.value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.industryFF12.value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.industryFF48.value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot-encode\n",
    "data_to_learn = pd.get_dummies(data=data_to_learn, columns=['industryFF5', 'industryFF12', 'industryFF48'])\n",
    "data_to_predict = pd.get_dummies(data=data_to_predict, columns=['industryFF5', 'industryFF12', 'industryFF48'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange\n",
    "\n",
    "The exchange is either `NASDQ`, `NYSE` or `ÀMEX`. \n",
    "\n",
    "We hot-encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.exchange.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot-encode\n",
    "data_to_learn = pd.get_dummies(data=data_to_learn, columns=['exchange'])\n",
    "data_to_predict = pd.get_dummies(data=data_to_predict, columns=['exchange'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issuer\n",
    "\n",
    "`issuer` is unique. We assume it therefore gives no predictive value and we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.issuer.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.drop([\"issuer\"], axis=1, inplace=True)\n",
    "data_to_predict.drop([\"issuer\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `manager`\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "- Separate the managers (The managers are separated by `\\n`)\n",
    "\n",
    "#### Feature engineering\n",
    "\n",
    "- Add columns with the amount of managers (it might be useful)\n",
    "- Compute the average of the success rates of each manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.manager.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.reset_index(drop=True, inplace=True)\n",
    "data_to_predict.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.manager = data_to_learn.manager.apply(lambda x: set(x.split('\\n')))\n",
    "data_to_predict.manager = data_to_predict.manager.apply(lambda x: set(x.split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn['managerLength'] = data_to_learn.manager.apply(lambda x: len(x))\n",
    "data_to_predict['managerLength'] = data_to_predict.manager.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the index where the IPO is successful\n",
    "success = data_to_learn.closeDay1 > data_to_learn.offerPrice\n",
    "successful_index = success.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average of the success rates of each manager\n",
    "for i, managers in enumerate(data_to_learn.manager):\n",
    "    average_success_rates = []\n",
    "    for manager in managers:\n",
    "        average_success_rate = success[data_to_learn.manager.apply(lambda x: manager in x)].mean()\n",
    "        average_success_rates.append(average_success_rate)\n",
    "    data_to_learn.loc[i, 'managerSuccessAvg'] = np.array(average_success_rates).mean()\n",
    "        \n",
    "        \n",
    "for i, managers in enumerate(data_to_predict.manager):\n",
    "    average_success_rates = []\n",
    "    for manager in managers:\n",
    "        average_success_rate = success[data_to_learn.manager.apply(lambda x: manager in x)].mean()\n",
    "        average_success_rates.append(average_success_rate)\n",
    "    data_to_predict.loc[i, 'managerSuccessAvg'] = np.array(average_success_rates).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.drop('manager', axis=1, inplace=True)\n",
    "data_to_predict.drop('manager', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process `rf`\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "- Clean punctuation\n",
    "- Remove stopwords\n",
    "- Lemmatize\n",
    "- Lowercase\n",
    "\n",
    "#### Feature engineering\n",
    "\n",
    "- Store `rf` length, it might be useful\n",
    "- Create scores relating the similarity between rf entries\n",
    "    - Create a corpus where each document is a `rf` entry (1)\n",
    "    - Compute the TF-IDF representation of each of those documents\n",
    "    - Compute the **cosine-similarity** between **each** document's TF-IDF representation and **all** the TF-IDF representations of the **successful** IPO\n",
    "    - Store the success rate of the top 1, 10 and 100 similarity rf\n",
    "\n",
    "    When a new document appears:\n",
    "    - Compute the TF-IDF of this new document (using (1) as corpus)\n",
    "    - Compute the **cosine-similarity** of your new document's TF-IDF representation and **all** the TF-IDF representations of the **successful** IPO\n",
    "    - Store the success rate of the top 1, 10 and 100 similarity rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_to_learn.rf.apply(lambda x: len(x.split()))\n",
    "df.hist(bins=100)\n",
    "print(\"Mean rf word length: \", df.mean())\n",
    "print(\"Std rf word length: \", df.std())\n",
    "plt.title(\"Histogram of the risk factor's word length\")\n",
    "plt.xlabel(\"Risk factor's word length\")\n",
    "plt.ylabel(\"Occurences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import corpus\n",
    "\n",
    "stopwords = set(corpus.stopwords.words('english'))\n",
    "\n",
    "def clean_re(txt):\n",
    "    return re.sub(r'[^\\w\\s]', '', txt) # We get rid of (non-words, non-whitespaces)\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    removed_txt = []\n",
    "    for token in txt.split():\n",
    "        if not token in stopwords:\n",
    "            removed_txt.append(token)\n",
    "    return ' '.join(removed_txt)\n",
    "\n",
    "def lemmatize_text(txt):\n",
    "    wnl = nltk.stem.WordNetLemmatizer() # maybe use a better lemmatizer eventually \n",
    "    \n",
    "    lemmatized_txt = []\n",
    "    for token in txt.split():\n",
    "        lemmatized_txt.append(wnl.lemmatize(token))\n",
    "    return ' '.join(lemmatized_txt).strip()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = clean_re(txt)\n",
    "    txt = remove_stopwords(txt.lower())\n",
    "    txt = lemmatize_text(txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.rf = data_to_learn.rf.apply(preprocess_text)\n",
    "data_to_predict.rf = data_to_predict.rf.apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn['rfLength'] = data_to_learn.rf.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the index where the IPO is successful\n",
    "success = data_to_learn.closeDay1 > data_to_learn.offerPrice\n",
    "successful_index = success.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the TF-IDF score of each rf entry\n",
    "tf_idf_vectorizer = TfidfVectorizer(ngram_range=(1,3), min_df=0)\n",
    "tf_idf_vectorizer.fit(data_to_learn.rf)\n",
    "tf_idf_matrix = tf_idf_vectorizer.transform(data_to_learn.rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the **average cosine-similarity** between **each** document's TF-IDF representation and top1, top10 and top100 of the TF-IDF representations of the **successful** IPO\n",
    "for i, _ in enumerate(data_to_learn.rf):\n",
    "    cosine_similarities = linear_kernel(tf_idf_matrix[i], tf_idf_matrix[successful_index]).flatten()\n",
    "    top_cosine_similarities_index = [j for j in cosine_similarities.argsort()[::-1] if i != j]\n",
    "    data_to_learn.loc[i, 'rfSuccessAvgTop1'] = success[top_cosine_similarities_index[0:1]].mean()\n",
    "    data_to_learn.loc[i, 'rfSuccessAvgTop10'] = success[top_cosine_similarities_index[0:10]].mean()\n",
    "    data_to_learn.loc[i, 'rfSuccessAvgTop100'] = success[top_cosine_similarities_index[0:100]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the **average cosine-similarity** between **each** document's TF-IDF representation and top1, top10 and top100 of the TF-IDF representations of the **successful** IPO\n",
    "for i, rf in enumerate(data_to_predict.rf):\n",
    "    cosine_similarities = linear_kernel(tf_idf_vectorizer.transform(rf), tf_idf_matrix[successful_index]).flatten()\n",
    "    top_cosine_similarities_index = [j for j in cosine_similarities.argsort()[::-1] if i != j]\n",
    "    data_to_predict.loc[i, 'rfSuccessAvgTop1'] = success[top_cosine_similarities_index[0:1]].mean()\n",
    "    data_to_predict.loc[i, 'rfSuccessAvgTop10'] = success[top_cosine_similarities_index[0:10]].mean()\n",
    "    data_to_predict.loc[i, 'rfSuccessAvgTop100'] = success[top_cosine_similarities_index[0:100]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.drop('rf', axis=1, inplace=True)\n",
    "data_to_predict.drop('rf', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn.to_pickle('data_to_learn.pkl')\n",
    "data_to_predict.to_pickle('data_to_predict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn = pd.read_pickle('data_to_learn.pkl')\n",
    "data_to_predict = pd.read_pickle('data_to_predict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_to_learn[0:100].corr()\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(data=df, xticklabels=df.columns, square=True, annot=True, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floatCols = data_to_learn.loc[:, data_to_learn.dtypes == float].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = []\n",
    "for col in floatCols:\n",
    "    mean = data_to_learn[col].mean()\n",
    "    std = data_to_learn[col].std()\n",
    "    for i,value in enumerate(data_to_learn[col]):\n",
    "        if value < mean-7*std or value > mean+7*std:\n",
    "            print('Outlier in', col, 'at index', i)\n",
    "            outliers.append([col, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_to_learn['nExecutives'].iloc[60:64]) #ça a l'air suspect par exemple..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.dummy           import DummyClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.ensemble        import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.metrics         import confusion_matrix\n",
    "from sklearn.metrics         import roc_auc_score\n",
    "from sklearn.metrics         import roc_curve\n",
    "\n",
    "\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9']\n",
    "X_to_predict = data_to_predict[list(set(data_to_predict.columns) - set(prediction_labels))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction P1\n",
    "\n",
    "- Predict whether the **closing price at the end of the first day** (i.e. `closeDay1`) of trading will go up (the \"positive\" case, coded as 1) or down (the \"negative\" case, coded as 0) from the **offer price** `offerPrice`. You may use all data from the dataset except for the rf variable (i.e., risk factors).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary\n",
    "\n",
    "We want to predict whether the offer price is **underpriced** or **overpriced**.\n",
    "\n",
    "The **label to predict** is **\"Is offer price underpriced ?\"**. \n",
    "\n",
    "Therefore, \n",
    "- **False Positives** are especially **costly**, (we would actually lose money) \n",
    "- **False Negatives are not costly** (we would simply miss an opportunity to make money) \n",
    "- **True Positives** make us money \n",
    "- **True Negatives** avoid us losing money.\n",
    "\n",
    "Let's use the AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset to learn from\n",
    "y = data_to_learn['closeDay1'] > data_to_learn['offerPrice']\n",
    "\n",
    "X = data_to_learn.drop(['closeDay1', 'rfSuccessAvgTop1', 'rfSuccessAvgTop10', 'rfSuccessAvgTop100'], axis=1) # We remove the features engineered from rf\n",
    "\n",
    "# For now, we discard the city, the managers and issuer. Later, hot-encode or something\n",
    "X.drop(['city', 'manager', 'issuer'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into test, train, validation sets\n",
    "\n",
    "From the data to train from, 20% is test set, 20% is train set and 20% is test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by extracting our test set (20% of all data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED, stratify=y)\n",
    "\n",
    "# We then divide our initial training set into our actual training set and our validation set (20%)\n",
    "X_train_train, X_train_val, y_train_train, y_train_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=SEED, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "steps = []\n",
    "steps.append(('standardize', StandardScaler()))\n",
    "steps.append(('knn_model', KNeighborsClassifier()))\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune K\n",
    "results = []\n",
    "for k in range(1, 100, 5):\n",
    "    pipeline.set_params(knn_model__n_neighbors=k) \n",
    "    pipeline.fit(X_train_train, y_train_train)\n",
    "    y_train_val_hat_prob = pipeline.predict_proba(X_train_val)[:,1]\n",
    "    auc = roc_auc_score(y_train_val, y_train_val_hat_prob)\n",
    "    results.append((auc, k))\n",
    "\n",
    "# View results \n",
    "results = pd.DataFrame(results)\n",
    "results.columns = ['AUC', 'K']\n",
    "sns.lineplot(x='K', y='AUC', data=results)\n",
    "plt.axhline(y=0.5, c='r', linestyle='--', label='Random')\n",
    "plt.legend()\n",
    "plt.title('AUC score compared for KNN for different K')\n",
    "print('Max AUC with K: ', results[results.AUC == results.AUC.max()].K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "steps = []\n",
    "steps.append(('forest_model', RandomForestClassifier(random_state=SEED)))\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune N   \n",
    "results = []\n",
    "for n in range(1, 100, 5):\n",
    "    pipeline.set_params(forest_model__n_estimators = n) \n",
    "    pipeline.fit(X_train_train, y_train_train)\n",
    "    y_train_pred = pipeline.predict_proba(X_train_val)\n",
    "    auc = roc_auc_score(y_train_val, y_train_pred[:,1])\n",
    "    results.append( (auc, n))\n",
    "\n",
    "# View results \n",
    "results = pd.DataFrame(results)\n",
    "results.columns = ['AUC', 'N']\n",
    "sns.lineplot(x='N', y='AUC', data=results)\n",
    "plt.axhline(y=0.5, c='r', linestyle='--', label='Random')\n",
    "plt.legend()\n",
    "plt.title('AUC score compared for Random Forest for different N')\n",
    "print('Max AUC with N: ', results[results.AUC == results.AUC.max()].N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "steps.append(('standardize', StandardScaler()))                            # standardize features\n",
    "steps.append(('logit_model_l1', LogisticRegression(random_state=SEED)))    # use a logit model\n",
    "logit_pipeline = Pipeline(steps)\n",
    "logit_pipeline.set_params(logit_model_l1__penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for c in np.linspace(1, 400, 401):\n",
    "    logit_pipeline.set_params(logit_model_l1__C=c) \n",
    "    logit_pipeline.fit(X_train_train,y_train_train)\n",
    "    y_train_pred = logit_pipeline.predict_proba(X_train_val)       # use validation set during hyper-parameter tuning\n",
    "    auc_lml1 = roc_auc_score(y_train_val, y_train_pred[:,1])   \n",
    "    results.append([auc_lml1, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot([row[1] for row in results], [row[0] for row in results])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Optimizing for C');\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction P2\n",
    "\n",
    "- Predict whether the **closing price at the end of the first day** of trading will go up (the \"positive\" case, coded as 1) or down (the \"negative\" case, coded as 0) from the **offer price.** You may use only the **rf** (i.e., risk factors), **year**, and **industryFF12** variables for this prediction task. You may, however, perform additional text analysis of the rf variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset to learn from\n",
    "y = data_to_learn['closeDay1'] > data_to_learn['offerPrice']\n",
    "\n",
    "\n",
    "X = data_to_learn[['rfSuccessAvgTop1', \n",
    "                   'rfSuccessAvgTop10',\n",
    "                   'rfSuccessAvgTop100',\n",
    "                   'year'] + [industryFF12_column for industryFF12_column in data_to_learn.columns if industryFF12_column.startswith('industry')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction P3\n",
    "\n",
    "- Predict whether the closing price at the end of the first day of trading will go up (the \"positive\" case, coded as 1) or down (the \"negative\" case, coded as 0) from the offer price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction P4\n",
    "\n",
    "- Predict whether the closing price at the end of the first day of trading will go up by more than 20% from the original offer price (the \"positive\" case, coded as 1) or not (the \"negative\" case, coded as 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction P5\n",
    "\n",
    "- Predict whether the closing price at the end of the first day of trading will go down by more than 20% from the original offer price (the \"positive\" case, coded as 1) or not (the \"negative\" case, coded as 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction P6\n",
    "\n",
    "- Predict the share price at the end of the first day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction P7\n",
    "\n",
    "- Predict the probability that the closing price at the end of the first day of trading will go up by more than 5% from the original offer price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction P8\n",
    "\n",
    "- Predict the probability that the closing price at the end of the first day of trading will go up by more than 50% from the original offer price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction P9\n",
    "\n",
    "- Predict the probability that the closing price at the end of the first day of trading will go down (the \"positive\" case, coded as 1) or not (coded as 0) by more than 10% from the original offer price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
